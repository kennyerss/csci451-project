{
 "cells": [
  {
   "cell_type": "raw",
   "id": "9052ef04-9952-42c4-a5d4-a8a7f4b2fb0e",
   "metadata": {},
   "source": [
    "---\n",
    "title: Determining Race from Chest X-Rays\n",
    "author: Trong Le, Jay-U Chung, Kent Canonigo\n",
    "date: '2023-05-10'\n",
    "image: 'view1_frontal.jpg'\n",
    "description: \"We used deep learning to guess a patient's race based on their chest X-ray.\"\n",
    "format: html\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ffe0ef5-6bb6-4e63-85e5-1690f882628c",
   "metadata": {},
   "source": [
    "# 1. Abstract\n",
    "\n",
    "For this project, we aim to make a model that can guess with high accuracy someone's race just by looking at their chest X-ray. By using pretrained EfficientNet and ResNet models, we made a machine that can predict whether a patient is Asian, Black or White with over 75% certainty and no gender bias.\n",
    "\n",
    "The GitHub repository for the project code can be found [here](https://github.com/kennyerss/csci451-project)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bffc2452-d5c5-415f-b107-5cf349f26a7c",
   "metadata": {},
   "source": [
    "# 2. Introduction\n",
    "\n",
    "It is understandable that medical information about a patient can be extracted from their chest X-ray. However, [Adleberg et. al](https://pubmed.ncbi.nlm.nih.gov/35964688/) created a model that can extract non-medical information such as age, gender, race, ethnicity and insurance status with almost 100% certainty. Similarly, [Gichoya et. al](https://www.thelancet.com/journals/landig/article/PIIS2589-7500(22)00063-2/fulltext) also successfully created a model that can predict race from chest X-rays.\n",
    "\n",
    "Our primary concern with this project is whether it is possible to detect race from such racially ambiguous data as chest X-rays, and what it means ethically if racial classification can be done this way. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53955aea-6377-48c6-8b38-fd3254c91d22",
   "metadata": {},
   "source": [
    "White patients occupy the vast majority of this dataset, as shown by the following figure, and we are concerned that this may lead to a racial bias in the model's classification algorithm.\n",
    "\n",
    "![imbalance](imbalance.png)\n",
    "\n",
    "To account for this imbalance, we trained our model on a racially balanced subset of the ChexPert dataset. Even though there are more male than female patients in this training set, we will learn later that the model does not exhibit gender bias.\n",
    "\n",
    "![balance1](balance.png) ![balance2](gender.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ml-0451] *",
   "language": "python",
   "name": "conda-env-ml-0451-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
