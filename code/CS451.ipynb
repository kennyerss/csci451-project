{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DO0PPvKwbESx",
    "outputId": "40d2bfab-79d7-4585-e3de-31df4115af15"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#need to import Drive\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcolab\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m drive\n\u001b[1;32m      4\u001b[0m drive\u001b[38;5;241m.\u001b[39mmount(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/content/drive\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'google'"
     ]
    }
   ],
   "source": [
    "#need to import Drive\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 406
    },
    "id": "sQ5gQxOiMElR",
    "outputId": "c1fa29e2-0e49-4241-b68f-e484c4c61295"
   },
   "outputs": [],
   "source": [
    "#This just will show the images\n",
    "\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "img = cv2.imread('/content/drive/MyDrive/chexpert_small/train/patient02330/study1/view1_frontal.jpg',1)\n",
    "#cv2.imshow()\n",
    "plt.imshow(img)\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TQd1clDCGfGA"
   },
   "outputs": [],
   "source": [
    "from os import walk\n",
    "for (dirpath, dirnames, filenames) in walk(\"../input/\"):\n",
    "    print(\"Directory path: \", dirpath)\n",
    "    print(\"Folder name: \", dirnames)\n",
    "#     print(\"File name: \", filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "id": "eL7Hjyd9GprE",
    "outputId": "e8e8a3dd-75a3-408b-892b-ffaebbf6a335"
   },
   "outputs": [],
   "source": [
    "# DO NOT RUN THIS\n",
    "\n",
    "\"\"\"\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "transform = transforms.Compose([transforms.Resize(255),\n",
    "                                 transforms.CenterCrop(224),\n",
    "                                 transforms.ToTensor()])\n",
    "\n",
    "dataset = datasets.ImageFolder('/content/drive/MyDrive/chexpert_small/train/', transform=transform)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "gVCX3wZLscbk",
    "outputId": "f11a08d9-280a-42c9-de66-84c88a7c334d"
   },
   "outputs": [],
   "source": [
    "# import our race data set and load as a dataframe\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df_train_race = pd.read_excel('/content/drive/MyDrive/chexpert_small/chexpert_race.xlsx')\n",
    "df_train_race"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xwGL98ahwin5",
    "outputId": "4e4048d6-39f3-4ef6-96fd-01557e8ee857"
   },
   "outputs": [],
   "source": [
    "# print the unique labels for race - we need to make some determinations here\n",
    "print(df_train_race['PRIMARY_RACE'].unique())\n",
    "print((df_train_race['PRIMARY_RACE'] == 'White, non-Hispanic').sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x8eaDvl6tCWj"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "from torch import optim\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision\n",
    "\n",
    "from fastprogress import master_bar, progress_bar\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "#I used a lot of code from https://www.kaggle.com/code/hmchuong/chexpert-pytorch-densenet121?scriptVersionId=18314696&cellId=15\n",
    "\n",
    "class ChestXrayDataset(Dataset):\n",
    "  #creates a Torch Dataset that we can use to do machine learning on\n",
    "\n",
    "  def __init__(self,folder_dir,dataframe,image_labels,image_size,normalization):\n",
    "    #a lot of this function is \n",
    "    # folder_dir is the directory path to the data\n",
    "    # dataframe holds patient info and labels\n",
    "    # it takes in our image labels\n",
    "\n",
    "    self.image_paths=[]\n",
    "    #self.image_labels=[]\n",
    "    self.image_labels=[]\n",
    "\n",
    "    #This transforms our image, I think we would also need normalization\n",
    "    image_transformation = [\n",
    "        transforms.Resize((image_size,image_size)),\n",
    "        transforms.ToTensor()\n",
    "    ]\n",
    "\n",
    "    #this normalizes using some constants from imagenet\n",
    "    if normalization:\n",
    "      image_transformation.append(transforms.Normalize(IMAGENET_MEAN,IMAGENET_STD))\n",
    "    \n",
    "    self.image_transformation = transforms.Compose(image_transformation)\n",
    "\n",
    "    #this will index through all the patients from 000001, so forth, adding images from study1\n",
    "    for index, row in dataframe.iterrows():\n",
    "      image_path = os.path.join(folder_dir,Path(row['PATIENT']),Path('study1'),Path('view1_frontal.jpg'))\n",
    "      self.image_paths.append(image_path)\n",
    "      #in this case I've hard-coded the image_labels to be if the patient is Black or not\n",
    "      #NOTICE that I'm append a list to a list here\n",
    "      if ( row[\"PRIMARY_RACE\"] ==  'White' or row[\"PRIMARY_RACE\"] == 'White, non-Hispanic' or row[\"PRIMARY_RACE\"] == 'White or Caucasian'):\n",
    "      #if ( row[\"PRIMARY_RACE\"] ==  'Black or African American' or row[\"PRIMARY_RACE\"] == 'Black, non-Hispanic'):\n",
    "        self.image_labels.append([1])\n",
    "      else:\n",
    "        self.image_labels.append([0])\n",
    "      #self.image_labels.append([int(1*((row[\"PATIENT\"] == 'Black or African American') | (row[\"PATIENT\"] == 'Black, non-Hispanic')))])\n",
    "    \n",
    "    #print(self.image_paths)\n",
    "\n",
    "  def __len__(self):\n",
    "    #I think this is necessary for other things\n",
    "    return len(self.image_paths)\n",
    "\n",
    "  def __getitem__(self,index):\n",
    "    #This is also just necessary for other parts\n",
    "\n",
    "    # Read image\n",
    "    image_path = self.image_paths[index]\n",
    "    image_data = Image.open(image_path).convert(\"RGB\")\n",
    "    image_data = self.image_transformation(image_data)\n",
    "      \n",
    "    return image_data, torch.FloatTensor(self.image_labels[index])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "biYVf-UmzLrP"
   },
   "outputs": [],
   "source": [
    "IMAGE_SIZE = 224                              # Image size (224x224)\n",
    "IMAGENET_MEAN = [0.485, 0.456, 0.406]         # Mean of ImageNet dataset (used for normalization)\n",
    "IMAGENET_STD = [0.229, 0.224, 0.225]          # Std of ImageNet dataset (used for normalization)\n",
    "BATCH_SIZE = 16                              \n",
    "LEARNING_RATE = 0.001\n",
    "LEARNING_RATE_SCHEDULE_FACTOR = 0.1           # Parameter used for reducing learning rate\n",
    "LEARNING_RATE_SCHEDULE_PATIENCE = 5           # Parameter used for reducing learning rate\n",
    "MAX_EPOCHS = 2                              # Maximum number of training epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RefbtJSi0rkv",
    "outputId": "5530b236-f6d9-4b71-d06f-012a3332801e"
   },
   "outputs": [],
   "source": [
    "race_is_black = ((df_train_race['PRIMARY_RACE'] == 'Black or African American')  | (df_train_race['PRIMARY_RACE'] =='Black, non-Hispanic'))\n",
    "race_is_black.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "50B9QepkvE0Y",
    "outputId": "9b20aa98-3fde-40f1-e86e-c6d5ed81cd0b"
   },
   "outputs": [],
   "source": [
    "race_is_white = ((df_train_race['PRIMARY_RACE'] == 'White')  | (df_train_race['PRIMARY_RACE'] =='White, non-Hispanic') | (df_train_race['PRIMARY_RACE'] =='White or Caucasian'))\n",
    "race_is_white.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "HdF9N-SW3dT9",
    "outputId": "7ba4d75e-f9b7-4f0f-b9fb-d78d84730be3"
   },
   "outputs": [],
   "source": [
    "df_train_race_mod = df_train_race.sort_values(by=['PATIENT'])[:2000]\n",
    "df_train_race_mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yTau2PnF43r_",
    "outputId": "c7ea602b-a969-4f2a-da51-bb66e5b5a06e"
   },
   "outputs": [],
   "source": [
    "race_is_black = ((df_train_race_mod['PRIMARY_RACE'] == 'Black or African American')  | (df_train_race_mod['PRIMARY_RACE'] =='Black, non-Hispanic'))\n",
    "race_is_black.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mNMbS_ORfjXf",
    "outputId": "d32e0444-64fd-466c-8b41-f59166456194"
   },
   "outputs": [],
   "source": [
    "df_train_race_mod_test = df_train_race.sort_values(by=['PATIENT'])[2000:2400]\n",
    "test_race_is_black = ((df_train_race_mod_test['PRIMARY_RACE'] == 'Black or African American')  | (df_train_race_mod_test['PRIMARY_RACE'] =='Black, non-Hispanic'))\n",
    "test_race_is_black.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RlA8mvyg4dYH",
    "outputId": "218e0a2c-3f34-454e-85e7-1c5afad8ed83"
   },
   "outputs": [],
   "source": [
    "'patient00090' < 'patient00010'\n",
    "len([1,3,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4mG56QTH9VBq",
    "outputId": "7e0abc9b-741b-42e2-d162-f679bbe54771"
   },
   "outputs": [],
   "source": [
    "race_is_black.tolist()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GxFhY7Glv44a",
    "outputId": "1c2e33b3-fa1d-4f64-a6d2-b9d329c5f5a5"
   },
   "outputs": [],
   "source": [
    "race_is_white = ((df_train_race_mod['PRIMARY_RACE'] == 'White')  | (df_train_race_mod['PRIMARY_RACE'] =='White, non-Hispanic') | (df_train_race_mod['PRIMARY_RACE'] =='White or Caucasian'))\n",
    "race_is_white.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YxA-OJMK0eKs"
   },
   "outputs": [],
   "source": [
    "train_dataset = ChestXrayDataset(\"/content/drive/MyDrive/chexpert_small/train\", df_train_race_mod, race_is_white, IMAGE_SIZE, True)\n",
    "#print(ChestXrayDataset.len(train_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "v0VxCabA6pWZ",
    "outputId": "d5a518cf-c481-4f83-95da-21f5d4417c0d"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "print(train_dataset.image_labels)\n",
    "print(np.array(train_dataset.image_labels).flatten().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZZd3fX5j0owJ"
   },
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, num_workers=2, shuffle=True, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "neiTnUgt24iP",
    "outputId": "afa89e26-b63f-4b2d-a96d-9d5c54ca6c5c"
   },
   "outputs": [],
   "source": [
    "#I believe that this functions as a test - if this block returns an error, there is a problem with dataloading\n",
    "for data, label in train_dataloader:\n",
    "    print(data.size())\n",
    "    print(label.size())\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "79av_y-6yWCq"
   },
   "outputs": [],
   "source": [
    "#FORGET THE COLUMNS below, I was trying to implement an algorithm to see if it worked, but it crashes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gST4oF51A81B"
   },
   "outputs": [],
   "source": [
    "#device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W0Faxh96BXDH"
   },
   "outputs": [],
   "source": [
    "def train(model,  data_loader, optimizer, k_epochs = 1, print_every = 2000):\n",
    "\n",
    "    begin = time.time()\n",
    "    # loss function is cross-entropy (multiclass logistic)\n",
    "    loss_fn = nn.CrossEntropyLoss() \n",
    "\n",
    "    # optimizer is Adam, which does fancier stuff with the gradients\n",
    "    \n",
    "    for epoch in range(k_epochs): \n",
    "\n",
    "        running_loss = 0.0\n",
    "\n",
    "        i = 0\n",
    "\n",
    "        #for i, data in enumerate(data_loader, 0):\n",
    "        for data,label in data_loader:  \n",
    "            #print(data.size())\n",
    "\n",
    "            # extract a batch of training data from the data loader\n",
    "            X = data\n",
    "            y = torch.flatten(label)\n",
    "            #y = label\n",
    "            y = y.to(torch.long)\n",
    "            X = X.to(device)\n",
    "            y = y.to(device)\n",
    "\n",
    "            \n",
    "\n",
    "            # zero out gradients: we're going to recompute them in a moment\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # compute the loss (forward pass)\n",
    "            y_hat = model(X)\n",
    "\n",
    "            #print(\"Here!\")\n",
    "            #print(y_hat)\n",
    "            #print(y)\n",
    "\n",
    "            loss = loss_fn(y_hat, y)\n",
    "\n",
    "            #print(\"All good here!\")\n",
    "\n",
    "            # compute the gradient (backward pass)\n",
    "            loss.backward()\n",
    "\n",
    "            # Adam uses the gradient to update the parameters\n",
    "            optimizer.step()\n",
    "\n",
    "            # print statistics\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            # print the epoch, number of batches processed, and running loss \n",
    "            # in regular intervals\n",
    "            if i % print_every == print_every - 1: \n",
    "            #if True:   \n",
    "                print(f'[epoch: {epoch + 1}, batches: {i + 1:5d}], training loss: {running_loss / print_every:.3f}')\n",
    "                #print(loss.item())\n",
    "                running_loss = 0.0\n",
    "\n",
    "            #print(i)\n",
    "            \n",
    "            i += 1\n",
    "    end = time.time()\n",
    "    print(f'Finished training in {round(end - begin)}s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x9ojxi8tBkxd"
   },
   "outputs": [],
   "source": [
    "from scipy.sparse import coo_array\n",
    "def test(model, data_loader):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    # torch.no_grad creates an environment in which we do NOT store the \n",
    "    # computational graph. We don't need to do this because we don't care about \n",
    "    # gradients unless we're training\n",
    "\n",
    "    i = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        #for data in data_loader:\n",
    "        for data, label in data_loader:\n",
    "\n",
    "            #print(data.size())\n",
    "            #print(label.size())\n",
    "\n",
    "            X = data\n",
    "            y = torch.flatten(label)\n",
    "            #X, y = data\n",
    "            X = X.to(device)\n",
    "            y = y.to(device)\n",
    "            \n",
    "            # run all the images through the model\n",
    "            y_hat = model(X)\n",
    "\n",
    "            # the class with the largest model output is the prediction\n",
    "            _, predicted = torch.max(y_hat.data, 1)\n",
    "\n",
    "            # compute the accuracy\n",
    "            total += y.size(0)\n",
    "            correct += (predicted == y).sum().item()\n",
    "\n",
    "            i += 1\n",
    "\n",
    "    print(i)\n",
    "    print(correct)\n",
    "    print(total)\n",
    "    print(f'Test accuracy: {100 * correct // total} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gaklnGKlBmmq"
   },
   "outputs": [],
   "source": [
    "from torchvision import models\n",
    "\n",
    "# instead train only the parameters of the final layer\n",
    "# can be around 50% faster\n",
    "\n",
    "model = models.resnet18(weights='IMAGENET1K_V1')\n",
    "model = model.to(device)\n",
    "\n",
    "# no gradients for any of the model parameters, so no updates\n",
    "\n",
    "for param in model.parameters():\n",
    "  param.requires_grad = False\n",
    "\n",
    "# Parameters of newly constructed modules have requires_grad=True by default\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs, 2)\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "# Observe that only parameters of final layer are being optimized as\n",
    "# opposed to before.\n",
    "optimizer = optim.Adam(model.fc.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fmi3jUy6DdxM"
   },
   "outputs": [],
   "source": [
    "from torchsummary import summary\n",
    "\n",
    "#summary(model, (3,224,224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PrguwFEnEKZL",
    "outputId": "47ee26e0-9ca6-4de8-dded-38c004f6790b"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "df_val_race_mod = df_train_race.sort_values(by=['PATIENT'])[2000:2321]\n",
    "\n",
    "race_is_black_val = ((df_val_race_mod['PRIMARY_RACE'] == 'Black or African American')  | (df_val_race_mod['PRIMARY_RACE'] =='Black, non-Hispanic'))\n",
    "#race_is_black.sum()\n",
    "\n",
    "race_is_white_val = ((df_val_race_mod['PRIMARY_RACE'] == 'White')  | (df_val_race_mod['PRIMARY_RACE'] =='White, non-Hispanic') | (df_val_race_mod['PRIMARY_RACE'] =='White or Caucasian'))\n",
    "print(race_is_white_val.sum())\n",
    "\n",
    "#val_dataset = ChestXrayDataset(\"/content/drive/MyDrive/chexpert_small/train\", df_val_race_mod, race_is_black_val, IMAGE_SIZE, True)\n",
    "\n",
    "val_dataset = ChestXrayDataset(\"/content/drive/MyDrive/chexpert_small/train\", df_val_race_mod, race_is_white_val, IMAGE_SIZE, True)\n",
    "\n",
    "val_dataloader = DataLoader(dataset=val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2, pin_memory=True)\n",
    "\n",
    "train(model, train_dataloader, optimizer, k_epochs = 5, print_every = 40)\n",
    "test(model,val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wZXJC0ITlgEu",
    "outputId": "1a009a44-1631-441f-f8e4-679a1dc32add"
   },
   "outputs": [],
   "source": [
    "df_val_race_mod = df_train_race.sort_values(by=['PATIENT'])[2000:2321]\n",
    "\n",
    "race_is_black_val = ((df_val_race_mod['PRIMARY_RACE'] == 'Black or African American')  | (df_val_race_mod['PRIMARY_RACE'] =='Black, non-Hispanic'))\n",
    "\n",
    "print(race_is_black_val.sum())\n",
    "print(df_val_race_mod.shape)\n",
    "print(100*(1-race_is_black_val.sum()/df_val_race_mod.shape[0]))\n",
    "\n",
    "val_dataset = ChestXrayDataset(\"/content/drive/MyDrive/chexpert_small/train\", df_val_race_mod, race_is_black_val, IMAGE_SIZE, True)\n",
    "\n",
    "print(BATCH_SIZE)\n",
    "\n",
    "val_dataloader = DataLoader(dataset=val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2, pin_memory=True)\n",
    "\n",
    "test(model,val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "1GVBBjamme4Q",
    "outputId": "b9306517-0774-4e26-ff8c-54fab0650c62"
   },
   "outputs": [],
   "source": [
    "df_val_race_mod = df_train_race.sort_values(by=['PATIENT'])[2000:2321]\n",
    "df_val_race_mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "S6yCR4rZe5BG",
    "outputId": "7f93e6be-57f2-4279-947c-68a885336c7b"
   },
   "outputs": [],
   "source": [
    "test(model,val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 169
    },
    "id": "Pf3eDcLbb2by",
    "outputId": "1ac3a9e4-1b4a-4fc1-cbdc-84bf7ff534c6"
   },
   "outputs": [],
   "source": [
    "print(running_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hybjgvoBMH-Y"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F #this is for relu\n",
    "\n",
    "class ConvNet(nn.Module): #inherits from nn.module\n",
    "\n",
    "  def __init__(self):\n",
    "    super().__init__() #run init method of parent class\n",
    "\n",
    "    \"\"\"\n",
    "    Let's just define the functions we'll use later for forward\n",
    "    \"\"\"\n",
    "\n",
    "    self.conv1 = nn.Conv2d(3, 100, 5) #3 input channels for rgb, 100 convolutional kernels, all size 5 by 5\n",
    "    self.conv2 = nn.Conv2d(100, 50, 3)\n",
    "    self.conv3 = nn.Conv2d(50, 20, 3)\n",
    "\n",
    "    self.pool = nn.MaxPool2d(2,2) #largest pixel value from each 2 by 2 window\n",
    "    self.fc1 = nn.Linear(13520,80)\n",
    "    self.fc2 = nn.Linear(80,40)\n",
    "    self.fc3 = nn.Linear(40,2) #only two outputs for the binary cat/dog label\n",
    "\n",
    "  def forward(self,x):\n",
    "    print('x_shape:',x.shape)\n",
    "    x = self.pool(F.relu(self.conv1(x))) #do kernel convolution to x, then do relu, then do max pooling\n",
    "    x = self.pool(F.relu(self.conv2(x)))\n",
    "    x = self.pool(F.relu(self.conv3(x)))\n",
    "\n",
    "    print('x_shape:',x.shape)\n",
    "\n",
    "    #DO NOT FORGET TO FLATTEN BEFORE LINEAR LAYERS\n",
    "\n",
    "    x = torch.flatten(x,1)\n",
    "\n",
    "    print('x_shape:',x.shape)\n",
    "\n",
    "    x = F.relu(self.fc1(x))\n",
    "\n",
    "    print('x_shape:',x.shape)\n",
    "\n",
    "    x = F.relu(self.fc2(x))\n",
    "\n",
    "    print('x_shape:',x.shape)\n",
    "\n",
    "    x = self.fc3(x) #just return the output, no nonlinear lyaers\n",
    "\n",
    "    print('x_shape:',x.shape)\n",
    "\n",
    "    return x\n",
    "\n",
    "model = ConvNet().to(device)\n",
    "\n",
    "import torch\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "train(model, train_dataloader, optimizer, k_epochs = 100, print_every = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_6RLBG8lb0aY"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "M7h_SqfpHybh",
    "outputId": "11f26150-65a2-4d42-cf1c-3450fc7383eb"
   },
   "outputs": [],
   "source": [
    "model = DenseNet121(num_classes = 2 ).to(device)\n",
    "model.train()\n",
    "train(model, train_dataloader, optimizer, k_epochs = 100, print_every = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j8RIbywjDOZG"
   },
   "outputs": [],
   "source": [
    "\n",
    "class DenseNet121(nn.Module):\n",
    "    def __init__(self, num_classes, is_trained=True):\n",
    "        \"\"\"\n",
    "        Init model architecture\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        num_classes: int\n",
    "            number of classes\n",
    "        is_trained: bool\n",
    "            whether using pretrained model from ImageNet or not\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        \n",
    "        # Load the DenseNet121 from ImageNet\n",
    "        self.net = torchvision.models.densenet121(pretrained=is_trained)\n",
    "        \n",
    "        # Get the input dimension of last layer\n",
    "        kernel_count = self.net.classifier.in_features\n",
    "        \n",
    "        # Replace last layer with new layer that have num_classes nodes, after that apply Sigmoid to the output\n",
    "        self.net.classifier = nn.Sequential(nn.Linear(kernel_count, num_classes), nn.Sigmoid())\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        \"\"\"\n",
    "        Forward the netword with the inputs\n",
    "        \"\"\"\n",
    "        return self.net(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cn_hX6LADRre"
   },
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SAgHCWUoDUE3"
   },
   "outputs": [],
   "source": [
    "model = DenseNet121(num_classes=2).to(device) #binary classification\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nNeVjZgsDl-M"
   },
   "outputs": [],
   "source": [
    "sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OISZYtFGDqFv"
   },
   "outputs": [],
   "source": [
    "# Loss function\n",
    "loss_criteria = nn.BCELoss()\n",
    "\n",
    "# Adam optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE, betas=(0.9, 0.999), eps=1e-8, weight_decay=1e-5)\n",
    "\n",
    "# Learning rate will be reduced automatically during training\n",
    "lr_scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor = LEARNING_RATE_SCHEDULE_FACTOR, patience = LEARNING_RATE_SCHEDULE_PATIENCE, mode = 'max', verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CTWXEKB2DuhA"
   },
   "outputs": [],
   "source": [
    "def multi_label_auroc(y_gt, y_pred):\n",
    "    \"\"\" Calculate AUROC for each class\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    y_gt: torch.Tensor\n",
    "        groundtruth\n",
    "    y_pred: torch.Tensor\n",
    "        prediction\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    list\n",
    "        F1 of each class\n",
    "    \"\"\"\n",
    "    auroc = []\n",
    "    gt_np = y_gt.to(\"cpu\").numpy()\n",
    "    pred_np = y_pred.to(\"cpu\").numpy()\n",
    "    assert gt_np.shape == pred_np.shape, \"y_gt and y_pred should have the same size\"\n",
    "    for i in range(gt_np.shape[1]):\n",
    "        auroc.append(roc_auc_score(gt_np[:, i], pred_np[:, i]))\n",
    "    return auroc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HAJf3-ImDvXr"
   },
   "outputs": [],
   "source": [
    "def epoch_training(epoch, model, train_dataloader, device, loss_criteria, optimizer, mb):\n",
    "    \"\"\"\n",
    "    Epoch training\n",
    "\n",
    "    Paramteters\n",
    "    -----------\n",
    "    epoch: int\n",
    "      epoch number\n",
    "    model: torch Module\n",
    "      model to train\n",
    "    train_dataloader: Dataset\n",
    "      data loader for training\n",
    "    device: str\n",
    "      \"cpu\" or \"cuda\"\n",
    "    loss_criteria: loss function\n",
    "      loss function used for training\n",
    "    optimizer: torch optimizer\n",
    "      optimizer used for training\n",
    "    mb: master bar of fastprogress\n",
    "      progress to log\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "      training loss\n",
    "    \"\"\"\n",
    "    # Switch model to training mode\n",
    "    model.train()\n",
    "    training_loss = 0 # Storing sum of training losses\n",
    "   \n",
    "    # For each batch\n",
    "    for batch, (images, labels) in enumerate(progress_bar(train_dataloader, parent=mb)):\n",
    "        \n",
    "        # Move X, Y  to device (GPU)\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # Clear previous gradient\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Feed forward the model\n",
    "        pred = model(images)\n",
    "        loss = loss_criteria(pred, labels)\n",
    "\n",
    "        # Back propagation\n",
    "        loss.backward()\n",
    "\n",
    "        # Update parameters\n",
    "        optimizer.step()\n",
    "\n",
    "        # Update training loss after each batch\n",
    "        training_loss += loss.item()\n",
    "\n",
    "        mb.child.comment = f'Training loss {training_loss/(batch+1)}'\n",
    "\n",
    "    del images, labels, loss\n",
    "    if torch.cuda.is_available(): torch.cuda.empty_cache()\n",
    "\n",
    "    # return training loss\n",
    "    return training_loss/len(train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0d9nqxHhD077"
   },
   "outputs": [],
   "source": [
    "def evaluating(epoch, model, val_loader, device, loss_criteria, mb):\n",
    "    \"\"\"\n",
    "    Validate model on validation dataset\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    epoch: int\n",
    "        epoch number\n",
    "    model: torch Module\n",
    "        model used for validation\n",
    "    val_loader: Dataset\n",
    "        data loader of validation set\n",
    "    device: str\n",
    "        \"cuda\" or \"cpu\"\n",
    "    loss_criteria: loss function\n",
    "      loss function used for training\n",
    "    mb: master bar of fastprogress\n",
    "      progress to log\n",
    "  \n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        loss on validation set\n",
    "    float\n",
    "        metric score on validation set\n",
    "    \"\"\"\n",
    "\n",
    "    # Switch model to evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    val_loss = 0                                   # Total loss of model on validation set\n",
    "    out_pred = torch.FloatTensor().to(device)      # Tensor stores prediction values\n",
    "    out_gt = torch.FloatTensor().to(device)        # Tensor stores groundtruth values\n",
    "\n",
    "    with torch.no_grad(): # Turn off gradient\n",
    "        # For each batch\n",
    "        for step, (images, labels) in enumerate(progress_bar(val_loader, parent=mb)):\n",
    "            # Move images, labels to device (GPU)\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # Update groundtruth values\n",
    "            out_gt = torch.cat((out_gt,  labels), 0)\n",
    "\n",
    "            # Feed forward the model\n",
    "            ps = model(images)\n",
    "            loss = loss_criteria(ps, labels)\n",
    "\n",
    "            # Update prediction values\n",
    "            out_pred = torch.cat((out_pred, ps), 0)\n",
    "\n",
    "            # Update validation loss after each batch\n",
    "            val_loss += loss\n",
    "            mb.child.comment = f'Validation loss {val_loss/(step+1)}'\n",
    "\n",
    "    # Clear memory\n",
    "    del images, labels, loss\n",
    "    if torch.cuda.is_available(): torch.cuda.empty_cache()\n",
    "    # return validation loss, and metric score\n",
    "    return val_loss/len(val_loader), np.array(multi_label_auroc(out_gt, out_pred)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iO_tL4RvD6pT"
   },
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2bNq51xXEQIz"
   },
   "outputs": [],
   "source": [
    "!pip install git+https://github.com/fastai/fastai --upgrade\n",
    "\n",
    "!pip install git+https://github.com/fastai/fastprogress --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nRv756yiM7sS"
   },
   "outputs": [],
   "source": [
    "df_train_race_val = df_train_race.sort_values(by=['PATIENT'])[501:700]\n",
    "race_is_black = ((df_train_race_val['PRIMARY_RACE'] == 'Black or African American')  | (df_train_race_val['PRIMARY_RACE'] =='Black, non-Hispanic'))\n",
    "\n",
    "val_dataset = ChestXrayDataset(\"/content/drive/MyDrive/chexpert_small/train\", df_train_race_val, race_is_black, IMAGE_SIZE, True)\n",
    "val_dataloader = DataLoader(dataset=val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xZjWjzlAD8-g"
   },
   "outputs": [],
   "source": [
    "from fastprogress.fastprogress import master_bar, progress_bar\n",
    "from time import sleep\n",
    "\n",
    "# Best AUROC value during training\n",
    "best_score = 0\n",
    "model_path = \"densenet.pth\"\n",
    "training_losses = []\n",
    "validation_losses = []\n",
    "validation_score = []\n",
    "\n",
    "\n",
    "# Config progress bar\n",
    "mb = master_bar(range(MAX_EPOCHS))\n",
    "mb.names = ['Training loss', 'Validation loss', 'Validation AUROC']\n",
    "x = []\n",
    "\n",
    "nonimproved_epoch = 0\n",
    "start_time = time.time()\n",
    "\n",
    "# Training each epoch\n",
    "for epoch in mb:\n",
    "    #mb.first_bar.comment = f'Best AUROC score: {best_score}'\n",
    "    x.append(epoch)\n",
    "\n",
    "    # Training\n",
    "    train_loss = epoch_training(epoch, model, train_dataloader, device, loss_criteria, optimizer, mb)\n",
    "    mb.write('Finish training epoch {} with loss {:.4f}'.format(epoch, train_loss))\n",
    "    training_losses.append(train_loss)\n",
    "\n",
    "    # Evaluating\n",
    "    val_loss, new_score = evaluating(epoch, model, val_dataloader, device, loss_criteria, mb)\n",
    "    mb.write('Finish validation epoch {} with loss {:.4f} and score {:.4f}'.format(epoch, val_loss, new_score))\n",
    "    validation_losses.append(val_loss)\n",
    "    validation_score.append(new_score)\n",
    "\n",
    "    # Update learning rate\n",
    "    lr_scheduler.step(new_score)\n",
    "\n",
    "    # Update training chart\n",
    "    mb.update_graph([[x, training_losses], [x, validation_losses], [x, validation_score]], [0,epoch+1], [0,1])\n",
    "\n",
    "    # Save model\n",
    "    if best_score < new_score:\n",
    "        mb.write(f\"Improve AUROC from {best_score} to {new_score}\")\n",
    "        best_score = new_score\n",
    "        nonimproved_epoch = 0\n",
    "        torch.save({\"model\": model.state_dict(), \n",
    "                    \"optimizer\": optimizer.state_dict(), \n",
    "                    \"best_score\": best_score, \n",
    "                    \"epoch\": epoch, \n",
    "                    \"lr_scheduler\": lr_scheduler.state_dict()}, model_path)\n",
    "    else: \n",
    "        nonimproved_epoch += 1\n",
    "    if nonimproved_epoch > 10:\n",
    "        break\n",
    "        print(\"Early stopping\")\n",
    "    if time.time() - start_time > 3600*8:\n",
    "        break\n",
    "        print(\"Out of time\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5yp3POFmHWIR"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"/var/log/colab-jupyter.log\", \"r\") as fo:\n",
    "  for line in fo:\n",
    "    print(json.loads(line)['msg'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mC1XLDhn6S8A"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "img = cv2.imread(train_dataset.image_paths[446],1)\n",
    "#cv2.imshow()\n",
    "plt.imshow(img)\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lyqfpleh7dJQ"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python [conda env:ml-0451]",
   "language": "python",
   "name": "conda-env-ml-0451-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
